{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472849c9",
   "metadata": {},
   "source": [
    "# Clustering Textual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ee4b5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>End of the Road</td>\n",
       "      <td>Boyz II Men</td>\n",
       "      <td>[spoken]\\nGirl you know we belong together \\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Got Back</td>\n",
       "      <td>Sir Mix-a-Lot</td>\n",
       "      <td>[Intro]\\nOh, my, god. Becky, look at her butt....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jump</td>\n",
       "      <td>Kris Kross</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Save the Best for Last</td>\n",
       "      <td>Vanessa Williams</td>\n",
       "      <td>Sometimes the snow comes down in June\\n      S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baby-Baby-Baby</td>\n",
       "      <td>TLC</td>\n",
       "      <td>And you want my love\\nWell that's alright\\nWel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I Will Remember You</td>\n",
       "      <td>Amy Grant</td>\n",
       "      <td>I will be walking one day\\nDown a street far a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>We Got a Love Thang</td>\n",
       "      <td>CeCe Peniston</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Let's Get Rocked</td>\n",
       "      <td>Def Leppard</td>\n",
       "      <td>Do ya wanna get rocked \\n\\nLet's get, let's ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>They Want EFX</td>\n",
       "      <td>Das EFX</td>\n",
       "      <td>Bum stiggedy bum stiggedy bum, hon, I got the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I Can't Make You Love Me</td>\n",
       "      <td>Bonnie Raitt</td>\n",
       "      <td>Turn down the lights, turn down the bed \\nTurn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title            Artist  \\\n",
       "0            End of the Road       Boyz II Men   \n",
       "1              Baby Got Back     Sir Mix-a-Lot   \n",
       "2                       Jump        Kris Kross   \n",
       "3     Save the Best for Last  Vanessa Williams   \n",
       "4             Baby-Baby-Baby               TLC   \n",
       "..                       ...               ...   \n",
       "95       I Will Remember You         Amy Grant   \n",
       "96       We Got a Love Thang     CeCe Peniston   \n",
       "97          Let's Get Rocked       Def Leppard   \n",
       "98             They Want EFX           Das EFX   \n",
       "99  I Can't Make You Love Me      Bonnie Raitt   \n",
       "\n",
       "                                               Lyrics  \n",
       "0   [spoken]\\nGirl you know we belong together \\nI...  \n",
       "1   [Intro]\\nOh, my, god. Becky, look at her butt....  \n",
       "2                                                 NaN  \n",
       "3   Sometimes the snow comes down in June\\n      S...  \n",
       "4   And you want my love\\nWell that's alright\\nWel...  \n",
       "..                                                ...  \n",
       "95  I will be walking one day\\nDown a street far a...  \n",
       "96                                                NaN  \n",
       "97  Do ya wanna get rocked \\n\\nLet's get, let's ge...  \n",
       "98  Bum stiggedy bum stiggedy bum, hon, I got the ...  \n",
       "99  Turn down the lights, turn down the bed \\nTurn...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/lyrics/1992.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376736ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>End of the Road</td>\n",
       "      <td>Boyz II Men</td>\n",
       "      <td>[spoken]\\nGirl you know we belong together \\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Got Back</td>\n",
       "      <td>Sir Mix-a-Lot</td>\n",
       "      <td>[Intro]\\nOh, my, god. Becky, look at her butt....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Save the Best for Last</td>\n",
       "      <td>Vanessa Williams</td>\n",
       "      <td>Sometimes the snow comes down in June\\n      S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby-Baby-Baby</td>\n",
       "      <td>TLC</td>\n",
       "      <td>And you want my love\\nWell that's alright\\nWel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tears in Heaven</td>\n",
       "      <td>Eric Clapton</td>\n",
       "      <td>Would you know my name\\nIf I saw you in heaven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Just Take My Heart</td>\n",
       "      <td>Mr. Big</td>\n",
       "      <td>Written on piano, performed on guitar. Boom. \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>I Will Remember You</td>\n",
       "      <td>Amy Grant</td>\n",
       "      <td>I will be walking one day\\nDown a street far a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Let's Get Rocked</td>\n",
       "      <td>Def Leppard</td>\n",
       "      <td>Do ya wanna get rocked \\n\\nLet's get, let's ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>They Want EFX</td>\n",
       "      <td>Das EFX</td>\n",
       "      <td>Bum stiggedy bum stiggedy bum, hon, I got the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>I Can't Make You Love Me</td>\n",
       "      <td>Bonnie Raitt</td>\n",
       "      <td>Turn down the lights, turn down the bed \\nTurn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title            Artist  \\\n",
       "0            End of the Road       Boyz II Men   \n",
       "1              Baby Got Back     Sir Mix-a-Lot   \n",
       "2     Save the Best for Last  Vanessa Williams   \n",
       "3             Baby-Baby-Baby               TLC   \n",
       "4            Tears in Heaven      Eric Clapton   \n",
       "..                       ...               ...   \n",
       "65        Just Take My Heart           Mr. Big   \n",
       "66       I Will Remember You         Amy Grant   \n",
       "67          Let's Get Rocked       Def Leppard   \n",
       "68             They Want EFX           Das EFX   \n",
       "69  I Can't Make You Love Me      Bonnie Raitt   \n",
       "\n",
       "                                               Lyrics  \n",
       "0   [spoken]\\nGirl you know we belong together \\nI...  \n",
       "1   [Intro]\\nOh, my, god. Becky, look at her butt....  \n",
       "2   Sometimes the snow comes down in June\\n      S...  \n",
       "3   And you want my love\\nWell that's alright\\nWel...  \n",
       "4   Would you know my name\\nIf I saw you in heaven...  \n",
       "..                                                ...  \n",
       "65  Written on piano, performed on guitar. Boom. \\...  \n",
       "66  I will be walking one day\\nDown a street far a...  \n",
       "67  Do ya wanna get rocked \\n\\nLet's get, let's ge...  \n",
       "68  Bum stiggedy bum stiggedy bum, hon, I got the ...  \n",
       "69  Turn down the lights, turn down the bed \\nTurn...  \n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649de15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750d8e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[spoken]\\nGirl you know we belong together \\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Intro]\\nOh, my, god. Becky, look at her butt....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sometimes the snow comes down in June\\n      S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And you want my love\\nWell that's alright\\nWel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would you know my name\\nIf I saw you in heaven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Written on piano, performed on guitar. Boom. \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>I will be walking one day\\nDown a street far a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Do ya wanna get rocked \\n\\nLet's get, let's ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Bum stiggedy bum stiggedy bum, hon, I got the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Turn down the lights, turn down the bed \\nTurn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Lyrics\n",
       "0   [spoken]\\nGirl you know we belong together \\nI...\n",
       "1   [Intro]\\nOh, my, god. Becky, look at her butt....\n",
       "2   Sometimes the snow comes down in June\\n      S...\n",
       "3   And you want my love\\nWell that's alright\\nWel...\n",
       "4   Would you know my name\\nIf I saw you in heaven...\n",
       "..                                                ...\n",
       "65  Written on piano, performed on guitar. Boom. \\...\n",
       "66  I will be walking one day\\nDown a street far a...\n",
       "67  Do ya wanna get rocked \\n\\nLet's get, let's ge...\n",
       "68  Bum stiggedy bum stiggedy bum, hon, I got the ...\n",
       "69  Turn down the lights, turn down the bed \\nTurn...\n",
       "\n",
       "[70 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics = df.drop(columns=['Title', 'Artist']) \n",
    "df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94117345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70 entries, 0 to 69\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Lyrics  70 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 688.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_lyrics.info()\n",
    "#df_lyrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5f406",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Divide the song lyrics into sentences, and then sentences to words. Using nltk (Neural language tool kit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f29dad8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[spoken]\n",
      "Girl you know we belong together \n",
      "I have no time for you to be playing \n",
      "With my heart like this \n",
      "You'll be mine forever baby, you just see \n",
      "\n",
      "[verse]\n",
      "We belong together \n",
      "And you that I'm right \n",
      "Why do you play with my heart, \n",
      "hy do you play with my mind \n",
      "\n",
      "Said we'd be forever \n",
      "Said it'd never die \n",
      "How could you love me and leave me \n",
      "And never say good-bye \n",
      "\n",
      "When I can't sleep at night without holding you tight \n",
      "Girl, each time I try I just break down and cry \n",
      "Pain in my head oh I'd rather be dead \n",
      "Spinnin' around and around \n",
      "\n",
      "[Chorus:]\n",
      "Although we've come to the End Of The Road \n",
      "Still I can't let you go \n",
      "It's unnatural, you belong to me, I belong to you \n",
      "Come to the End of the Road \n",
      "Still I can't let you go \n",
      "It's unnatural, you belong to me, I belong to you \n",
      "\n",
      "Girl, I know you really love me, \n",
      "You just don't realize \n",
      "You've never been there before \n",
      "It's only your first time \n",
      "\n",
      "Maybe I'll forgive you, hmm \n",
      "Maybe you'll try \n",
      "We should be happy together \n",
      "Forever, you and I \n",
      "\n",
      "Can you love me again like you loved me before \n",
      "This time I want you to love me much more \n",
      "This time instead just come to my bed \n",
      "And baby just don't let me, don't let me down \n",
      "\n",
      "[Chorus]\n",
      "\n",
      "[spoken]\n",
      "Girl I'm here for you \n",
      "All those times of night when you just hurt me \n",
      "And just run out with that other fella \n",
      "Baby I knew about it, I just didn't care \n",
      "You just don't understand how much I love you do you \n",
      "I'm here for you \n",
      "\n",
      "I'm not out to go out and cheat on you all night \n",
      "Just like you did baby but that's all right \n",
      "Hey, I love you anyway \n",
      "And I'm still gonna be here for you 'till my dying day baby \n",
      "Right now, I'm just in so much pain baby \n",
      "Coz you just won't come back to me \n",
      "Will you Just come back to me \n",
      "\n",
      "(Lonely) \n",
      "Yes baby my heart is lonely \n",
      "(Lonely) \n",
      "My heart hurts baby \n",
      "(Lonely) \n",
      "Yes I feel pain too \n",
      "Baby please \n",
      "\n",
      "This time instead just come to my bed \n",
      "And baby just don't let me go \n",
      "\n",
      "[Chorus]\n",
      "\n",
      "[Chorus (a cappella)]\n"
     ]
    }
   ],
   "source": [
    "sentense = df_lyrics.iloc[0]['Lyrics']\n",
    "print(sentense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be448d85",
   "metadata": {},
   "source": [
    "### Remove '[spoken]' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881e7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "sentense = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", sentense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83de2680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Girl', 'you', 'know', 'we', 'belong', 'together', 'I', 'have', 'no', 'time', 'for', 'you', 'to', 'be', 'playing', 'With', 'my', 'heart', 'like', 'this', 'You', \"'ll\", 'be', 'mine', 'forever', 'baby', ',', 'you', 'just', 'see', 'We', 'belong', 'together', 'And', 'you', 'that', 'I', \"'m\", 'right', 'Why', 'do', 'you', 'play', 'with', 'my', 'heart', ',', 'hy', 'do', 'you', 'play', 'with', 'my', 'mind', 'Said', 'we', \"'d\", 'be', 'forever', 'Said', 'it', \"'d\", 'never', 'die', 'How', 'could', 'you', 'love', 'me', 'and', 'leave', 'me', 'And', 'never', 'say', 'good-bye', 'When', 'I', 'ca', \"n't\", 'sleep', 'at', 'night', 'without', 'holding', 'you', 'tight', 'Girl', ',', 'each', 'time', 'I', 'try', 'I', 'just', 'break', 'down', 'and', 'cry', 'Pain', 'in', 'my', 'head', 'oh', 'I', \"'d\", 'rather', 'be', 'dead', 'Spinnin', \"'\", 'around', 'and', 'around', 'Although', 'we', \"'ve\", 'come', 'to', 'the', 'End', 'Of', 'The', 'Road', 'Still', 'I', 'ca', \"n't\", 'let', 'you', 'go', 'It', \"'s\", 'unnatural', ',', 'you', 'belong', 'to', 'me', ',', 'I', 'belong', 'to', 'you', 'Come', 'to', 'the', 'End', 'of', 'the', 'Road', 'Still', 'I', 'ca', \"n't\", 'let', 'you', 'go', 'It', \"'s\", 'unnatural', ',', 'you', 'belong', 'to', 'me', ',', 'I', 'belong', 'to', 'you', 'Girl', ',', 'I', 'know', 'you', 'really', 'love', 'me', ',', 'You', 'just', 'do', \"n't\", 'realize', 'You', \"'ve\", 'never', 'been', 'there', 'before', 'It', \"'s\", 'only', 'your', 'first', 'time', 'Maybe', 'I', \"'ll\", 'forgive', 'you', ',', 'hmm', 'Maybe', 'you', \"'ll\", 'try', 'We', 'should', 'be', 'happy', 'together', 'Forever', ',', 'you', 'and', 'I', 'Can', 'you', 'love', 'me', 'again', 'like', 'you', 'loved', 'me', 'before', 'This', 'time', 'I', 'want', 'you', 'to', 'love', 'me', 'much', 'more', 'This', 'time', 'instead', 'just', 'come', 'to', 'my', 'bed', 'And', 'baby', 'just', 'do', \"n't\", 'let', 'me', ',', 'do', \"n't\", 'let', 'me', 'down', 'Girl', 'I', \"'m\", 'here', 'for', 'you', 'All', 'those', 'times', 'of', 'night', 'when', 'you', 'just', 'hurt', 'me', 'And', 'just', 'run', 'out', 'with', 'that', 'other', 'fella', 'Baby', 'I', 'knew', 'about', 'it', ',', 'I', 'just', 'did', \"n't\", 'care', 'You', 'just', 'do', \"n't\", 'understand', 'how', 'much', 'I', 'love', 'you', 'do', 'you', 'I', \"'m\", 'here', 'for', 'you', 'I', \"'m\", 'not', 'out', 'to', 'go', 'out', 'and', 'cheat', 'on', 'you', 'all', 'night', 'Just', 'like', 'you', 'did', 'baby', 'but', 'that', \"'s\", 'all', 'right', 'Hey', ',', 'I', 'love', 'you', 'anyway', 'And', 'I', \"'m\", 'still', 'gon', 'na', 'be', 'here', 'for', 'you', \"'till\", 'my', 'dying', 'day', 'baby', 'Right', 'now', ',', 'I', \"'m\", 'just', 'in', 'so', 'much', 'pain', 'baby', 'Coz', 'you', 'just', 'wo', \"n't\", 'come', 'back', 'to', 'me', 'Will', 'you', 'Just', 'come', 'back', 'to', 'me', 'Yes', 'baby', 'my', 'heart', 'is', 'lonely', 'My', 'heart', 'hurts', 'baby', 'Yes', 'I', 'feel', 'pain', 'too', 'Baby', 'please', 'This', 'time', 'instead', 'just', 'come', 'to', 'my', 'bed', 'And', 'baby', 'just', 'do', \"n't\", 'let', 'me', 'go', ']']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#function to split text into word\n",
    "tokens = word_tokenize(sentense)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35322b49",
   "metadata": {},
   "source": [
    "## Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acd1d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['girl', 'you', 'know', 'we', 'belong', 'together', 'i', 'have', 'no', 'time', 'for', 'you', 'to', 'be', 'playing', 'with', 'my', 'heart', 'like', 'this', 'you', \"'ll\", 'be', 'mine', 'forever', 'baby', ',', 'you', 'just', 'see', 'we', 'belong', 'together', 'and', 'you', 'that', 'i', \"'m\", 'right', 'why', 'do', 'you', 'play', 'with', 'my', 'heart', ',', 'hy', 'do', 'you', 'play', 'with', 'my', 'mind', 'said', 'we', \"'d\", 'be', 'forever', 'said', 'it', \"'d\", 'never', 'die', 'how', 'could', 'you', 'love', 'me', 'and', 'leave', 'me', 'and', 'never', 'say', 'good-bye', 'when', 'i', 'ca', \"n't\", 'sleep', 'at', 'night', 'without', 'holding', 'you', 'tight', 'girl', ',', 'each', 'time', 'i', 'try', 'i', 'just', 'break', 'down', 'and', 'cry', 'pain', 'in', 'my', 'head', 'oh', 'i', \"'d\", 'rather', 'be', 'dead', 'spinnin', \"'\", 'around', 'and', 'around', 'although', 'we', \"'ve\", 'come', 'to', 'the', 'end', 'of', 'the', 'road', 'still', 'i', 'ca', \"n't\", 'let', 'you', 'go', 'it', \"'s\", 'unnatural', ',', 'you', 'belong', 'to', 'me', ',', 'i', 'belong', 'to', 'you', 'come', 'to', 'the', 'end', 'of', 'the', 'road', 'still', 'i', 'ca', \"n't\", 'let', 'you', 'go', 'it', \"'s\", 'unnatural', ',', 'you', 'belong', 'to', 'me', ',', 'i', 'belong', 'to', 'you', 'girl', ',', 'i', 'know', 'you', 'really', 'love', 'me', ',', 'you', 'just', 'do', \"n't\", 'realize', 'you', \"'ve\", 'never', 'been', 'there', 'before', 'it', \"'s\", 'only', 'your', 'first', 'time', 'maybe', 'i', \"'ll\", 'forgive', 'you', ',', 'hmm', 'maybe', 'you', \"'ll\", 'try', 'we', 'should', 'be', 'happy', 'together', 'forever', ',', 'you', 'and', 'i', 'can', 'you', 'love', 'me', 'again', 'like', 'you', 'loved', 'me', 'before', 'this', 'time', 'i', 'want', 'you', 'to', 'love', 'me', 'much', 'more', 'this', 'time', 'instead', 'just', 'come', 'to', 'my', 'bed', 'and', 'baby', 'just', 'do', \"n't\", 'let', 'me', ',', 'do', \"n't\", 'let', 'me', 'down', 'girl', 'i', \"'m\", 'here', 'for', 'you', 'all', 'those', 'times', 'of', 'night', 'when', 'you', 'just', 'hurt', 'me', 'and', 'just', 'run', 'out', 'with', 'that', 'other', 'fella', 'baby', 'i', 'knew', 'about', 'it', ',', 'i', 'just', 'did', \"n't\", 'care', 'you', 'just', 'do', \"n't\", 'understand', 'how', 'much', 'i', 'love', 'you', 'do', 'you', 'i', \"'m\", 'here', 'for', 'you', 'i', \"'m\", 'not', 'out', 'to', 'go', 'out', 'and', 'cheat', 'on', 'you', 'all', 'night', 'just', 'like', 'you', 'did', 'baby', 'but', 'that', \"'s\", 'all', 'right', 'hey', ',', 'i', 'love', 'you', 'anyway', 'and', 'i', \"'m\", 'still', 'gon', 'na', 'be', 'here', 'for', 'you', \"'till\", 'my', 'dying', 'day', 'baby', 'right', 'now', ',', 'i', \"'m\", 'just', 'in', 'so', 'much', 'pain', 'baby', 'coz', 'you', 'just', 'wo', \"n't\", 'come', 'back', 'to', 'me', 'will', 'you', 'just', 'come', 'back', 'to', 'me', 'yes', 'baby', 'my', 'heart', 'is', 'lonely', 'my', 'heart', 'hurts', 'baby', 'yes', 'i', 'feel', 'pain', 'too', 'baby', 'please', 'this', 'time', 'instead', 'just', 'come', 'to', 'my', 'bed', 'and', 'baby', 'just', 'do', \"n't\", 'let', 'me', 'go', ']']\n"
     ]
    }
   ],
   "source": [
    "tokens=[word.lower() for word in tokens]\n",
    "# or better\n",
    "tokens = list(map(str.lower,tokens))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff651be7",
   "metadata": {},
   "source": [
    "## Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d40074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['girl', 'know', 'belong', 'together', 'time', 'playing', 'heart', 'like', \"'ll\", 'mine', 'forever', 'baby', ',', 'see', 'belong', 'together', \"'m\", 'right', 'play', 'heart', ',', 'hy', 'play', 'mind', 'said', \"'d\", 'forever', 'said', \"'d\", 'never', 'die', 'could', 'love', 'leave', 'never', 'say', 'good-bye', 'ca', \"n't\", 'sleep', 'night', 'without', 'holding', 'tight', 'girl', ',', 'time', 'try', 'break', 'cry', 'pain', 'head', 'oh', \"'d\", 'rather', 'dead', 'spinnin', \"'\", 'around', 'around', 'although', \"'ve\", 'come', 'end', 'road', 'still', 'ca', \"n't\", 'let', 'go', \"'s\", 'unnatural', ',', 'belong', ',', 'belong', 'come', 'end', 'road', 'still', 'ca', \"n't\", 'let', 'go', \"'s\", 'unnatural', ',', 'belong', ',', 'belong', 'girl', ',', 'know', 'really', 'love', ',', \"n't\", 'realize', \"'ve\", 'never', \"'s\", 'first', 'time', 'maybe', \"'ll\", 'forgive', ',', 'hmm', 'maybe', \"'ll\", 'try', 'happy', 'together', 'forever', ',', 'love', 'like', 'loved', 'time', 'want', 'love', 'much', 'time', 'instead', 'come', 'bed', 'baby', \"n't\", 'let', ',', \"n't\", 'let', 'girl', \"'m\", 'times', 'night', 'hurt', 'run', 'fella', 'baby', 'knew', ',', \"n't\", 'care', \"n't\", 'understand', 'much', 'love', \"'m\", \"'m\", 'go', 'cheat', 'night', 'like', 'baby', \"'s\", 'right', 'hey', ',', 'love', 'anyway', \"'m\", 'still', 'gon', 'na', \"'till\", 'dying', 'day', 'baby', 'right', ',', \"'m\", 'much', 'pain', 'baby', 'coz', 'wo', \"n't\", 'come', 'back', 'come', 'back', 'yes', 'baby', 'heart', 'lonely', 'heart', 'hurts', 'baby', 'yes', 'feel', 'pain', 'baby', 'please', 'time', 'instead', 'come', 'bed', 'baby', \"n't\", 'let', 'go', ']']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [w for w in tokens if not w in stop_words]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c41d6",
   "metadata": {},
   "source": [
    "## Alternativ 1: Stemming - Reduce complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acce4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer # Porter is most popular stemmer algorithm\n",
    "\n",
    "# init stemmer\n",
    "porter_stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1f5675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['girl', 'know', 'belong', 'togeth', 'time', 'play', 'heart', 'like', \"'ll\", 'mine', 'forev', 'babi', ',', 'see', 'belong', 'togeth', \"'m\", 'right', 'play', 'heart', ',', 'hy', 'play', 'mind', 'said', \"'d\", 'forev', 'said', \"'d\", 'never', 'die', 'could', 'love', 'leav', 'never', 'say', 'good-by', 'ca', \"n't\", 'sleep', 'night', 'without', 'hold', 'tight', 'girl', ',', 'time', 'tri', 'break', 'cri', 'pain', 'head', 'oh', \"'d\", 'rather', 'dead', 'spinnin', \"'\", 'around', 'around', 'although', \"'ve\", 'come', 'end', 'road', 'still', 'ca', \"n't\", 'let', 'go', \"'s\", 'unnatur', ',', 'belong', ',', 'belong', 'come', 'end', 'road', 'still', 'ca', \"n't\", 'let', 'go', \"'s\", 'unnatur', ',', 'belong', ',', 'belong', 'girl', ',', 'know', 'realli', 'love', ',', \"n't\", 'realiz', \"'ve\", 'never', \"'s\", 'first', 'time', 'mayb', \"'ll\", 'forgiv', ',', 'hmm', 'mayb', \"'ll\", 'tri', 'happi', 'togeth', 'forev', ',', 'love', 'like', 'love', 'time', 'want', 'love', 'much', 'time', 'instead', 'come', 'bed', 'babi', \"n't\", 'let', ',', \"n't\", 'let', 'girl', \"'m\", 'time', 'night', 'hurt', 'run', 'fella', 'babi', 'knew', ',', \"n't\", 'care', \"n't\", 'understand', 'much', 'love', \"'m\", \"'m\", 'go', 'cheat', 'night', 'like', 'babi', \"'s\", 'right', 'hey', ',', 'love', 'anyway', \"'m\", 'still', 'gon', 'na', \"'till\", 'die', 'day', 'babi', 'right', ',', \"'m\", 'much', 'pain', 'babi', 'coz', 'wo', \"n't\", 'come', 'back', 'come', 'back', 'ye', 'babi', 'heart', 'lone', 'heart', 'hurt', 'babi', 'ye', 'feel', 'pain', 'babi', 'pleas', 'time', 'instead', 'come', 'bed', 'babi', \"n't\", 'let', 'go', ']']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words=[porter_stemmer.stem(word=word) for word in tokens]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf04c95",
   "metadata": {},
   "source": [
    "## Alternativ 2:  Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a63619b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>lemmatized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belong</td>\n",
       "      <td>belong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>together</td>\n",
       "      <td>together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>baby</td>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>n't</td>\n",
       "      <td>n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>let</td>\n",
       "      <td>let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>]</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    original_word lemmatized_word\n",
       "0            girl            girl\n",
       "1            know            know\n",
       "2          belong          belong\n",
       "3        together        together\n",
       "4            time            time\n",
       "..            ...             ...\n",
       "198          baby            baby\n",
       "199           n't             n't\n",
       "200           let             let\n",
       "201            go              go\n",
       "202             ]               ]\n",
       "\n",
       "[203 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in tokens]\n",
    "lemmatizeddf= pd.DataFrame({'original_word': tokens,'lemmatized_word': lemmatized_words})\n",
    "lemmatizeddf=lemmatizeddf[['original_word','lemmatized_word']]\n",
    "lemmatizeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "932eaf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizeddf.to_csv ('data/Lyrics/lemmatization_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb91fff",
   "metadata": {},
   "source": [
    " ## Scrub the text - With Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03e0035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter_stemmer=PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19651633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belong</td>\n",
       "      <td>belong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>together</td>\n",
       "      <td>togeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>baby</td>\n",
       "      <td>babi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>n't</td>\n",
       "      <td>n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>let</td>\n",
       "      <td>let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>]</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     raw_word stemmed_word\n",
       "0        girl         girl\n",
       "1        know         know\n",
       "2      belong       belong\n",
       "3    together       togeth\n",
       "4        time         time\n",
       "..        ...          ...\n",
       "198      baby         babi\n",
       "199       n't          n't\n",
       "200       let          let\n",
       "201        go           go\n",
       "202         ]            ]\n",
       "\n",
       "[203 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem raw words with noise\n",
    "\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in tokens]\n",
    "stemdf= pd.DataFrame({'raw_word': tokens,'stemmed_word': stemmed_words})\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "635622fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_words(text):\n",
    "    \"\"\"Basic cleaning of texts.\"\"\"\n",
    "    \n",
    "    # remove html markup\n",
    "    text=re.sub(\"(<.*?>)\",\"\",text)\n",
    "    \n",
    "    #remove non-ascii and digits\n",
    "    text=re.sub(\"(\\\\W|\\\\d)\",\" \",text)\n",
    "    \n",
    "    #remove whitespace\n",
    "    text=text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afe09b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_word</th>\n",
       "      <th>cleaned_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belong</td>\n",
       "      <td>belong</td>\n",
       "      <td>belong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>together</td>\n",
       "      <td>together</td>\n",
       "      <td>togeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>baby</td>\n",
       "      <td>baby</td>\n",
       "      <td>babi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>n't</td>\n",
       "      <td>n t</td>\n",
       "      <td>n t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>let</td>\n",
       "      <td>let</td>\n",
       "      <td>let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     raw_word cleaned_word stemmed_word\n",
       "0        girl         girl         girl\n",
       "1        know         know         know\n",
       "2      belong       belong       belong\n",
       "3    together     together       togeth\n",
       "4        time         time         time\n",
       "..        ...          ...          ...\n",
       "198      baby         baby         babi\n",
       "199       n't          n t          n t\n",
       "200       let          let          let\n",
       "201        go           go           go\n",
       "202         ]                          \n",
       "\n",
       "[203 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem words already cleaned\n",
    "cleaned_words=[scrub_words(w) for w in tokens]\n",
    "cleaned_stemmed_words=[porter_stemmer.stem(word=word) for word in cleaned_words]\n",
    "stemdf= pd.DataFrame({'raw_word': tokens,'cleaned_word':cleaned_words,'stemmed_word': cleaned_stemmed_words})\n",
    "stemdf=stemdf[['raw_word','cleaned_word','stemmed_word']]\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e92893d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemdf['stemmed_word'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5775ed7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_word</th>\n",
       "      <th>cleaned_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belong</td>\n",
       "      <td>belong</td>\n",
       "      <td>belong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>together</td>\n",
       "      <td>together</td>\n",
       "      <td>togeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>bed</td>\n",
       "      <td>bed</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>baby</td>\n",
       "      <td>baby</td>\n",
       "      <td>babi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>n't</td>\n",
       "      <td>n t</td>\n",
       "      <td>n t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>let</td>\n",
       "      <td>let</td>\n",
       "      <td>let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     raw_word cleaned_word stemmed_word\n",
       "0        girl         girl         girl\n",
       "1        know         know         know\n",
       "2      belong       belong       belong\n",
       "3    together     together       togeth\n",
       "4        time         time         time\n",
       "..        ...          ...          ...\n",
       "197       bed          bed          bed\n",
       "198      baby         baby         babi\n",
       "199       n't          n t          n t\n",
       "200       let          let          let\n",
       "201        go           go           go\n",
       "\n",
       "[186 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the weird ']'\n",
    "stemdf = stemdf.dropna()\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b964b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemdf.to_csv ('data/Lyrics/stemmed_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a05fa5",
   "metadata": {},
   "source": [
    "#### There is a bunch of words like:\n",
    "\n",
    "- 'll      meaning  will (Like in I'll = I will)\n",
    "- 've      should've ( Should have)\n",
    "- 'd       I'd ( I would)\n",
    "- ca       can't (can)\n",
    "- n't      can't (not)\n",
    "- 'm       I'm (am)\n",
    "- 'till    (untill)\n",
    "- coz      (because)\n",
    "- good by  good-bye (goodbye)\n",
    "\n",
    "Maybe i should look for those words? or maybe that's a distinct writing style, that can help categories the song texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f350c",
   "metadata": {},
   "source": [
    "#### Maybe i can get some inspiration from here: https://kvsingh.github.io/lyrics-sentiment-analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666260f",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4bf3a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "df_abstracts_tfidf = tfidf.fit_transform(stemdf[\"stemmed_word\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7bd08",
   "metadata": {},
   "source": [
    "#### OBS! Need to change this. The dataframe should be of all the songs.. The one i use rigth now, is a df of words from the first song.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d658648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.053763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.226159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             babi\n",
       "count  186.000000\n",
       "mean     0.053763\n",
       "std      0.226159\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      0.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=250, strip_accents=\"unicode\", min_df=10, max_df=200)\n",
    "tfidf_religion_array = tfidf.fit_transform(stemdf[\"stemmed_word\"])\n",
    "df_abstracts_tfidf = pd.DataFrame(tfidf_religion_array.toarray(), index=stemdf.index, columns=tfidf.get_feature_names())\n",
    "df_abstracts_tfidf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f177481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
